# -*- coding: utf-8 -*-
"""ML_MP2_Q4_Ghorbani.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b_exw6kJZ943Tmcta3FEmUbO29lLrAYd

# Q4
Use [Naive bayse](https://scikit-learn.org/stable/modules/naive_bayes.html) classifier for [Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset). This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes, including the predicted attribute, but all published experiments refer to using a subset of 14 of them. The "target" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.

# Part I
"""

# Import libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

"""A) Import dataset"""

# Import datasets as .csv
!pip install --upgrade --no-cach-dir gdown
! gdown 1WyoEdhQHi-sp7yBnk5WzgvkO-otUJaI0

dataset = pd.read_csv('/content/heart.csv')
pd.DataFrame(dataset).head()

X = np.array(dataset.loc[:,dataset.columns!='target'])
y = np.array(dataset.loc[:,dataset.columns =='target'])
print(X.shape, y.shape)

dataset.info()

# Check balancing
plt.rcParams["figure.figsize"] = (10, 5)
sns.countplot(x='target', data=dataset)

plt.rcParams["figure.figsize"] = (12, 10)
dataset.hist()

"""B) Preprocessing data"""

# Shuffle both X and y with same order
X_shuffled, y_shuffled = shuffle(X,y, random_state = 24)

# split dataset
x_train , x_test , y_train , y_test = train_test_split(X_shuffled, y_shuffled,
                                                       test_size = 0.2,
                                                       random_state = 24
                                                       )
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)

# Standardize dataset
scaler = StandardScaler()
scaler.fit(x_train)


x_train_normalized = scaler.transform(x_train)
x_test_normalized = scaler.transform(x_test)

print(np.mean(x_train), np.std(x_train))
print(np.mean(x_train_normalized), np.std(x_train_normalized))

"""# Part II"""

clf = GaussianNB()

clf.fit(x_train_normalized ,y_train.ravel())

y_pred = clf.predict(x_test_normalized)

y_pred = y_pred.reshape(-1,1)
y_pred.shape, y_test.shape

accuracy_score(y_test, y_pred)

"""# Part III"""

print(classification_report(y_test, y_pred))

plt.rcParams["figure.figsize"] = (10, 6)
cm = confusion_matrix(y_test, y_pred)
disp1 = ConfusionMatrixDisplay(confusion_matrix=cm)
disp1.plot(cmap='Blues')

y_rand_pred = []
y_rand_label =[]

for i in range(5):
  random_choice = np.random.default_rng().integers(1, x_test.shape[0], size=1)
  y_rand_label.append(y_test[random_choice])
  y_rand_pred.append(clf.predict(x_test_normalized[random_choice]))
  print(f'Sample {i+1} - Predicted={y_test[random_choice]}  Actual={clf.predict(x_test_normalized[random_choice])}')
  print('---------------------------')